<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="referrer" content="no-referrer">
    

    

    <link rel="icon" type="image/png" href="/favicon_16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon_32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/favicon_128x128.png" sizes="128x128">

    <title>
      
      
         Support Vector Machine 
      
    </title>
    <link rel="canonical" href="https://hellosilicat.github.io/posts/svm/">
	<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

	
    <style>
* {
    border: 0;
    font: inherit;
    font-size: 100%;
    vertical-align: baseline;
    margin: 0;
    padding: 0;
    color: black;
    text-decoration-skip: ink;
}

.round_avatar {
    width: 63px;
    height: 63px;
    display: flex;
    border-radius: 50%;
    align-items: center;
    justify-content: center;
    overflow: hidden;
}

body {
    font-family: 'century gothic', 'texgyreadventor', 'stheiti', 'Times New Roman', 'Open Sans', 'Myriad Pro', Myriad, sans-serif;
    font-size: 17px;
    line-height: 140%;
    color: #1d1313;
    max-width: 700px;
    margin: auto;
    padding: 0px;
}

table {
    display: table;
    border-collapse: separate;
    border-spacing: 2px;
    border-color: black;
    border: 1px;
}

p {
    margin: 20px 0;
}

a img {
    border: none;
}

img {
    border: 1px solid #ddd;
    border-radius: 4px;
    padding: 1px;
    box-shadow: 0 0 2px 1px rgba(0, 0, 0, 0.5);
    margin: 15px auto 15px auto;
    max-width: 100%;
    display: block;
}

.left-justify {
    float: left;
}

.right-justify {
    float: right;
}

pre,
code {
    font: 12px Consolas, "Liberation Mono", Menlo, Courier, monospace;
    background-color: #f7f7f7;
}

code {
    font-size: 12px;
    padding: 0px;
}

pre {
    margin-top: 0;
    margin-bottom: 16px;
    word-wrap: normal;
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
}

pre>code {
    padding: 0;
    margin: 0;
    font-size: 100%;
    word-break: normal;
    white-space: pre;
    background: transparent;
    border: 0;
}

pre code {
    display: inline;
    max-width: auto;
    padding: 0;
    margin: 0;
    overflow: visible;
    line-height: inherit;
    word-wrap: normal;
    background-color: transparent;
    border: 0;
}

pre code::before,
pre code::after {
    content: normal;
}

em,
q,
em,
dfn {
    font-style: italic;
}

.sans,
html .gist .gist-file .gist-meta {
    font-family: "Open Sans", "Myriad Pro", Myriad, sans-serif;
}

.mono,
pre,
code,
tt,
p code,
li code {
    font-family: Menlo, Monaco, "Andale Mono", "lucida console", "Courier New", monospace;
}

.heading,
.serif,
h1,
h2,
h3 {
    font-family: "KaTeX_Main", "Times New Roman", "Old Standard TT", serif;
}

strong {
    font-weight: 600;
}

q:before {
    content: "\201C";
}

q:after {
    content: "\201D";
}

del,
s {
    text-decoration: line-through;
}

blockquote {
    font-family: "Old Standard TT", serif;
    text-align: center;
    padding: 10px;
}

blockquote p {
    display: inline-block;
    font-style: italic;
}

blockquote:before,
blockquote:after {
    font-family: "Old Standard TT", serif;
    content: '\201C';
    font-size: 35px;
    color: #403c3b;
}

blockquote:after {
    content: '\201D';
}


hr {
    width: 100%;
    height: 1px;
    margin: 25px auto;
    border-top: 1px dashed grey;
}

h1 {
    font-size: 35px;
}

h2 {
    font-size: 28px;
}

h3 {
    font-size: 1.3em;
    font-weight: bold;
    margin-top: 18px;
    margin-bottom: 5px;
}

h1 a,
h2 a,
h3 a {
    text-decoration: none;
}

h1,
h2 {
    margin-top: 28px;
}

#sub-header,
time {
    color: #403c3b;
    font-size: 13px;
}

#sub-header {
    margin: 0 4px;
}

#nav h1 a {
    font-size: 1em;
    color: #1d1313;
    line-height: 100%;
}

.posts_listing a {
    border-bottom: 1px dashed grey;
    text-decoration: none;
}

#nav a {
    text-decoration: none;
}

li {
    margin-left: 20px;
}

ul li {
    margin-left: 5px;
}

ul li {
    list-style-type: none;
}

ul li:before {
    content: "\00BB \0020";
}

#nav ul li:before,
.posts_listing li:before {
    content: '';
    margin-right: 0;
}

#content {
    text-align: left;
    width: 100%;
    font-size: 15px;
    padding: 0px 0 80px;
}

#content h1,
#content h2 {
    margin-bottom: 5px;
}

#content h2 {
    font-size: 25px;
}

#content .entry-content {
    line-height: 120%;
    margin-top: 15px;
}

.entry-content p {
    margin-top: 0;
    margin-bottom: 2px;
    text-indent: 2rem;
}

.entry-content blockquote {
    text-indent: 0rem;
}

.entry-content ul,
ol,
dl {
    margin-left: 1rem;
}

#content time {
    margin-left: 3px;
}

#content h1 {
    font-size: 30px;
}

.highlight {
    margin: 10px 0;
}

.posts_listing {
    margin: 0 0 50px;
}

.posts_listing li {
    margin: 0 0 25px 15px;
}

.posts_listing td a:hover {
    text-decoration: none;
    border-bottom: none;
}

#nav a:hover {
    text-decoration: none;
}

#nav {
    text-align: center;
    position: static;
    margin-top: 0px;
    padding-top: 0px;
}

#nav ul {
    display: table;
    margin: 8px auto 0 auto;
}

#nav li {
    list-style-type: none;
    display: table-cell;
    font-size: 15px;
    padding: 0 20px;
}

#links {
    margin: 50px 0 0 0;
}

#links :nth-child(2) {
    float: right;
}

#not-found {
    text-align: center;
}

#not-found a {
    font-family: "Old Standard TT", serif;
    font-size: 200px;
    text-decoration: none;
    display: inline-block;
    padding-top: 225px;
}

@media (max-width: 750px) {
    body {
        padding-left: 20px;
        padding-right: 20px;
    }

    #nav h1 a {
        font-size: 28px;
    }

    #nav li {
        font-size: 13px;
        padding: 0 15px;
    }

    #content {
        margin-top: 0;
        padding-top: 50px;
        font-size: 14px;
    }

    #content h1 {
        font-size: 25px;
    }

    #content h2 {
        font-size: 22px;
    }

    .posts_listing li div {
        font-size: 12px;
    }
}

@media (max-width: 400px) {
    body {
        padding-left: 20px;
        padding-right: 20px;
    }

    #nav h1 a {
        font-size: 22px;
    }

    #nav li {
        font-size: 12px;
        padding: 0 10px;
    }

    #content {
        margin-top: 0;
        padding-top: 20px;
        font-size: 12px;
    }

    #content h1 {
        font-size: 20px;
    }

    #content h2 {
        font-size: 18px;
    }

    .posts_listing li div {
        font-size: 12px;
    }
}

@media (prefers-color-scheme: dark) {

    *,
    #nav h1 a {
        color: #FDFDFD;
    }

    body {
        background: #121212;
    }

    pre,
    code {
        background-color: #262626;
    }

    #sub-header,
    time {
        color: #BABABA;
    }

    hr {
        background: #EBEBEB;
    }
}
</style>


    
  </head>

<body>
    <section id=nav>
        <a href="/"><img src="/avatar.jpg" class="round_avatar" alt=""></a>
        <ul>
            
            <li><a href="/about/">About</a></li>
            
            <li><a href="/life/">Life</a></li>
            
            <li><a href="/">Sci &amp; Tech</a></li>
            
        </ul>
    </section>

<section id=content>
    
    <hr />
    <div class="entry-content">
        

<p>支持向量机(Support Vector Machine)既可以处理分类任务(SVC)，也可以处理回归任务(SVR)；既可以处理线性可分数据集(硬间隔SVM)，也能处理非线性可分数据集(软间隔SVM、核方法)。</p>

<hr />

<h3 id="1-线性svm">1. 线性SVM</h3>

<p>对于二分类线性可分数据集（正类表示为+1，负类表示为-1），设直线为$wx+b=0$能够分离不同类的样本点($wx+b&gt;0$为正类，反之负类)，定义与直线距离最近的点$x _\alpha(\alpha=1,2,&hellip;)$为支持向量，注意$y _i(wx _i+b)$的符号可以表示分类正确性(正代表分类正确，负表示分类错误)，则线性SVM的优化目标为直线到支持向量的距离最大，即：
$$\max \limits _{w,b} \frac{y _\alpha(wx _\alpha+b)}{||w||}$$
$$s.t. \frac{y _i(wx _i +b)}{||w||} \ge \frac{y _\alpha (wx _\alpha +b)}{||w||}$$</p>

<p>因为同比例改变$w,b$不影响直线位置/形状，所以若$y _\alpha(wx _ \alpha+b)=\lambda$，则$(\frac{1}{\lambda * y _ \alpha}w, \frac{1}{\lambda * y _\alpha}b)$也是解，因此不妨设$y          _\alpha (w x _\alpha +b)=1$，这样优化目标为(不等式两边同乘$|w|$)：
$$\max \limits _{w,b} \frac{1}{||w||}$$
$$s.t. y _i(wx _i +b) \ge 1$$</p>

<p>为进行凸优化，$max \frac{1}{||w||}$可写成$min \frac{1}{2}||w||^2$，这样线性SVM最终的优化目标为：
$$\min \limits _{w,b} \frac{1}{2}||w||^2$$
$$s.t. y _i(wx _i +b) \ge 1$$</p>

<p><a href="https://www.cnblogs.com/sddai/p/5728195.html">拉格朗日乘子法</a>对应的拉格朗日函数为：
$$L(w,b,\alpha) = \frac{1}{2} ||w||^2 + \sum _{i=1}^n \alpha _i (1 - y _i (wx _i +b))$$</p>

<p>简单写一下我对<a href="https://www.cnblogs.com/lijiankou/p/3308742.html">拉格朗日对偶性</a>的理解：原优化目标为凸函数，故对应的拉格朗日函数需求最小极值点，分别对未知参数求偏导等价于$\min \limits _{w,b} \max \limits _{\alpha} L(w,b,\alpha)$，$min$容易理解，为什么需要$max$呢，一旦存在某个$\alpha _i g(x)&gt; \alpha _{max}(x)$（g(x)是约束函数，小于等于零），那么$\alpha _{max}$就可以替换成$\alpha _{i}$从而使整个式子更小，算是节省了对$\alpha$求导的代价吧，拉格朗日对偶性是指在满足KKT条件后，上述极小极大问题等价于极大极小问题，即$$\max \limits _{\alpha} \min \limits _{w,b}  L(w,b,\alpha)$$</p>

<p>先求$\min \limits _{w,b} L(w,b,\alpha)$令$L$关于$w,b$的偏导为零可得：
$$w = \sum _{i=1}^n \alpha _i y _i x _i$$
$$0 = \sum _{i=1}^n \alpha _i y_i$$</p>

<p>代入拉格朗日函数得到：
$$L(\alpha) = \sum _{i=1}^n \alpha _i - \frac{1}{2} \sum _{i=1}^n \sum _{j=1}^n \alpha _i \alpha _j y _i y _j (x _i ^T x_j)$$</p>

<p>因此等价的对偶优化目标为：
$$\max \limits _{\alpha} L(\alpha)$$
$$s.t. \sum _{i=1}^n \alpha _i y_i = 0, \alpha _i \ge 0 $$</p>

<p>同时满足KKT条件：
$$\alpha _i \ge 0, \\\ y _i(w x _i  + b) - 1 \ge 0, \\\ \alpha _i (y _i(w x _i + b) - 1) = 0.$$</p>

<p>最终：
$$w = \sum _{i=1}^n \alpha _i y _i x _i$$
$$b = \frac{1- y _j w^Tx _j}{y _j}，其中\alpha _j &gt; 0(根据KKT条件推导)$$</p>

<p>观察到，$w$只和$\alpha _i \ne 0$的样本点有关，而根据KKT条件，这些样本点满足$y _i(w x _i  + b) = 1$，即支持向量，所以SVM模型在预测时仅和支持向量有关，这样的稀疏性大大降低了时间开销。</p>

<hr />

<h3 id="2-软间隔svm">2. 软间隔SVM</h3>

<p>对于非线性可分数据集，软间隔SVM允许部分样本点被分错，但是希望这样的错误越少越好，为了达到这样的目标，可以采取损失函数或者引入松弛变量的方法。</p>

<p>对应不同的损失函数，软间隔SVM的优化目标为(C为超参数，调节“软”的程度)：</p>

<ul>
<li>hinge损失: $\min \limits _{w,b} \frac{1}{2}||w||^2 + C\sum _{i=1}^n max(0, 1 - y_i(wx_i+b))$</li>
<li>指数损失:   $\min \limits _{w,b} \frac{1}{2}||w||^2 + C\sum _{i=1}^n e^{-1 + y_i(wx_i+b))}$</li>
<li>对率损失: $\min \limits _{w,b} \frac{1}{2}||w||^2 + C\sum _{i=1}^n log(1+e^{-1 + y_i(wx_i+b)})$</li>
</ul>

<p>可以通过引入松弛变量来表达软间隔SVM，其优化式为(引入$\xi$作为松弛变量，表达每个样本被分错的程度)：
$$\min \limits_{w,b,\xi} \frac{1}{2}||w||^2 + C \sum_{i=1}^{n}\xi _i$$
$$s.t. y_i(w^Tx_i+b)\ge 1-\xi _i$$
$$\xi _i \ge 0, i=1,2,&hellip;,n$$</p>

<p>同样，其拉格朗日函数为：
$$L(w,b,\alpha,\xi _i,\mu) = \frac{1}{2}||w||^2 + C\sum _{i=1}^{n}\xi _i+\sum _{i=1}^b \alpha _i(1-\xi _i-y _i(w^Tx _i+b)) - \sum_{i=1}^n \mu _i\xi _i$$</p>

<p>同样，先视拉格朗日乘子$\alpha,\mu$为常数，对$w,b,\xi$求偏导得：
$$w=\sum _{i=1}^n \alpha _i y_i x_i$$
$$\sum _{i=1}^n \alpha _iy_i$$
$$C = \alpha _i + \mu _i$$</p>

<p>代入得对偶问题：
$$\max \limits_{\alpha} \sum _{i=1}^n \alpha - \frac{1}{2}\sum _{i=1}^n \sum _{j=1}^n \alpha _i \alpha _j y_iy_jx_i^Tx_j$$
$$s.t. \sum _{i=1}^n \alpha _i y _i = 0,$$
$$0\le\alpha _i\le C,i=1,2,&hellip;,n$$</p>

<p>其KKT条件为：
$$\alpha _i \ge 0, \\\ \mu _i \ge 0, \\\ y _i(w x _i  + b) - 1+ \xi _i \ge 0, \\\ \xi _i \ge 0, \\\ \alpha _i (y _i(w x _i + b) - 1 + \xi) = 0, \\\ \mu _i \xi _i = 0$$</p>

<hr />

<h3 id="3-核方法">3. 核方法</h3>

<p>另一个针对非线性可分数据集的SVM是引入核方法，可证明：如果原始空间是有限集，即属性数有限，那么一定存在一个高维特征空间使样本可分。</p>

<p>引入$\phi$表示原始向量映射后的特征向量，则硬间隔SVM的优化目标可改写为：
$$\min \limits _{w,b} \frac{1}{2}||w||^2,$$
$$s.t. y_i(w^T\phi(x) _i + b) \ge 1$$</p>

<p>其拉格朗日对偶问题为：
$$\max \limits _{\alpha} \sum _{i=1}^n \alpha _i -\frac{1}{2} \sum _{i=1}^n \sum _{j=1} ^n \alpha _i \alpha _j y _i y _j \phi(x _i)^T \phi(x _j)$$
$$s.t. \sum _{i=1} ^ n \alpha _i y _i =0,$$
$$\alpha _i \ge 0, i = 1,2,&hellip;,n$$</p>

<p>我们发现对于对偶问题，只需要求得原始空间向量内积在映射空间的内积即可，定义核函数$K(x_i,x_j)$表达$x_i,x_j$在映射空间的内积，则求解对偶问题后可得：
\begin{equation}\begin{split}
f(x) &amp;= w^T\phi (x) + b \\<br />
&amp;= \sum _{i=1} ^ n \alpha _i y_i \phi (x_i)^T\phi (x_j) + b\\<br />
&amp; = \sum _{i=1} ^ n \alpha _i y _i K(x,x_i) + b
\end{split}\end{equation}</p>

<p>常见的核函数：</p>

<ul>
<li>线性核： $K(x,y) = x^Ty$</li>
<li>多项式核：$K(x,y)=(x^Ty)^d$</li>
<li>高斯核：$K(x,y)=e^{-\frac{||x-y||^2}{2\sigma ^2}}$</li>
</ul>

<hr />

<h3 id="4-支持向量回归">4. 支持向量回归</h3>

<p>支持向量的出发点是，对于每一个样本点，允许其出现偏差，上限为$e$，偏差超过$e$才开始计入，形式化为($||z|| &lt; e$时,$l(z)=0$，否则$l(z) = ||z||-e$)：
$$\min \limits _{w,b} \frac{1}{2} ||w||^2 + C \sum _{i=1}^{n} l(f(x_i),y_i)$$</p>

<p>引入松弛变量，SVR的优化目标为：
$$\min \limits _{w,b,\xi _i, \hat \xi _i} = \frac{1}{2} ||w||^2 + C \sum _{i=1}^n (\xi _i + \hat \xi _i)$$
$$s.t.  f(x_i)-y_i \le e+ \xi _i,$$
$$y_i - f(x_i) &lt;= e + \hat \xi _i$$
$$\xi _i \ge 0, \hat \xi _i \ge 0$$</p>

<p>对应的拉格朗日函数为：
\begin{equation}\begin{split}
L&amp;(w,b,\alpha,\hat \alpha, \mu, \hat \mu, \xi, \hat \xi)   \\<br />
&amp;= \frac{1}{2} ||w||^2 + C \sum _{i=1} ^ n (\xi _i + \hat \xi _j) - \sum _{i=1}^n \mu _i \xi _i - \sum _{i=1}^n \hat \mu \hat \xi _i \\<br />
&amp; + \sum _{i=1}^n \alpha _i (f(x_i)-y_i-e-\xi _i) + \sum _{i=1} ^ n \hat \alpha _i(y _i  - f(x _i) - e - \hat \xi _i)
\end{split}\end{equation}</p>

<p>对$w,b,\xi,\hat \xi$求偏导得：
$$w=\sum _{i=1} ^ b (\hat \alpha _i - \alpha _i)x _i,$$
$$0=\sum _{i=1}^n(\hat \alpha _i - \alpha _i),$$
$$C=\alpha _i + \mu _i,$$
$$C=\hat \alpha _i + \hat \mu _i$$</p>

<p>代入得对偶问题为：
$$\max \limits _{\alpha _i, \hat \alpha _i} \sum _{i=1}^n y_i(\hat \alpha _i - \alpha _i) - e(\hat \alpha _i + \alpha _i) - \frac{1}{2}\sum _{i=1}^n \sum _{j=1}^n (\hat \alpha _i - \alpha _i)(\hat \alpha _j - \alpha _j)x_i^Tx_j $$
$$s.t. \sum _{i=1}^n (\hat \alpha _i - \alpha _i) = 0,$$
$$0 \le \alpha _i, \hat \alpha _i \le C$$</p>

<hr />

<h4 id="参考资料">参考资料：</h4>

<ol>
<li>《机器学习》，周志华，清华大学出版社，2017</li>
</ol>

    </div>
    
    
    
</section>

</body>
</html>
