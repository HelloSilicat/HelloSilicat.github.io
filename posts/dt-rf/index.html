<!DOCTYPE html>
<html lang="en">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  
  
  
  
  <link rel="prev" href="https://hellosilicat.github.io/posts/2lr/" />
  <link rel="next" href="https://hellosilicat.github.io/posts/svm/" />
  <link rel="canonical" href="https://hellosilicat.github.io/posts/dt-rf/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           Decision Tree and Random Forest | Jialiang Pei
       
  </title>
  <meta name="title" content="Decision Tree and Random Forest | Jialiang Pei">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https:\/\/hellosilicat.github.io\/"
    },
    "articleSection" : "posts",
    "name" : "Decision Tree and Random Forest",
    "headline" : "Decision Tree and Random Forest",
    "description" : " 1. 基础 信息熵(information entropy)： 度量样本集合纯度，越小越纯；若当前样本集合$D$中第$i$类样本所占的比例为$p_i(i=1,2,\x26hellip;,K)$，则信息熵定义为： $$Ent(D) = -\\sum _{i=1}^K p_i logp_i$$\n属性信息熵：度量样本集合按照特定属性分割后的信息熵；若样本集合在属性取$v$值时的子集为$D^v(v=1,2,\x26hellip;,V)$，则属性信息熵定义为： $$\\sum _{v=1}^V \\frac{|D^v|}{|D|}Ent(D^v)$$\n信息增益：度量样本集合根据特定属性$a$分割后信息熵降低水平，偏好类别数多的属性，信息增益越大，分割后纯度越大，定义为： $$Gain(D,a)=Ent(D) - \\sum _{v=1}^V \\frac{|D^v|}{|D|}Ent(D^v)$$\n信息增益率：度量样本集合根据特定属性$a$分割后信息熵降低程度，偏好类别数较少的属性，信息增益率越大，分割后纯度越大，定义为： $$Gain-ratio(D,a) = \\frac{Gain(D,a)}{-\\sum _{v=1}^V \\frac{|D^v|}{|D|} log\\frac{|D^v|}{|D|} }$$\n基尼系数：度量样本集合纯度，越小越纯(直观上代表从样本集合中抽出两个样本，它们类别不一致的概率)，定义为： $$Gini(D) = 1 - \\sum _{i=1}^K p_i^2$$\n属性基尼系数：度量样本集合按照特定属性$a$分割后纯度，越小越纯，定义为： $$Gini-index(D,a) = \\sum _{v=1}^V \\frac{|D^v|}{|D|}Gini(D^v)$$\n2. 决策树 ID3：分类树，采取信息增益率作为最优化分标准； C4.5：分类树，二分法离散化连续值，划分时，先选择信息增益高于平均水平的特征，再选择信息增益率最大的； CART：分类树\/回归树，作为分类树时以属性基尼系数作为最优划分标准；作为回归树时参考回归树 基本算法： 剪枝：预剪枝在构建决策树时评估是否会带来泛化性的提升而选择是否分隔，训练速度快但是容易欠拟合；后剪枝从构建的决策树自叶节点向上，若将叶节点与父节点合并会提升泛化性则进行合并； 3. 随机森林 Bagging(Bootstrap Aggregating)：每次不放回采样m个样本进行训练，得到T个模型，分类则投票法，回归则平均法；Bootstrap方法每次约能涵盖63.2%的原始样本，剩余的36.8%可用作包外估计； 随机森林：基学习器是决策树，在Bagging的基础上，每次划分特征时，先随机选择k个特征，然后在这些特征中选择最优的，最终投票产生结果； 参考资料：  《机器学习》，周志华，清华大学出版社，2017 《统计学习方法》，李航，清华大学出版社，2012  ",
    "inLanguage" : "en",
    "author" : "",
    "creator" : "",
    "publisher": "",
    "accountablePerson" : "",
    "copyrightHolder" : "",
    "copyrightYear" : "2019",
    "datePublished": "2019-10-14 14:04:29 \x2b0800 CST",
    "dateModified" : "2019-10-14 14:04:29 \x2b0800 CST",
    "url" : "https:\/\/hellosilicat.github.io\/posts\/dt-rf\/",
    "wordCount" : "58",
    "keywords" : [  "Jialiang Pei"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://hellosilicat.github.io/">Jialiang Pei</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/life/" title="">Life</a>
                
                <a class="menu-item" href="/" title="">Sci &amp; Tech</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://hellosilicat.github.io/">Jialiang Pei</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/life/" title="">Life</a>
                
                <a class="menu-item" href="/" title="">Sci &amp; Tech</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Decision Tree and Random Forest</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://hellosilicat.github.io/" rel="author"></a> with ♥ 
                <span class="post-time">
                on <time datetime=2019-10-14 itemprop="datePublished">October 14, 2019</time>
                </span>
                in
                
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          

<h3 id="1-基础">1. 基础</h3>

<h4 id="信息熵-information-entropy-度量样本集合纯度-越小越纯-若当前样本集合-d-中第-i-类样本所占的比例为-p-i-i-1-2-k-则信息熵定义为"><strong>信息熵(information entropy)：</strong> 度量样本集合纯度，越小越纯；若当前样本集合$D$中第$i$类样本所占的比例为$p_i(i=1,2,&hellip;,K)$，则信息熵定义为：</h4>

<p>$$Ent(D) = -\sum _{i=1}^K p_i logp_i$$</p>

<h4 id="属性信息熵-度量样本集合按照特定属性分割后的信息熵-若样本集合在属性取-v-值时的子集为-d-v-v-1-2-v-则属性信息熵定义为"><strong>属性信息熵：</strong>度量样本集合按照特定属性分割后的信息熵；若样本集合在属性取$v$值时的子集为$D^v(v=1,2,&hellip;,V)$，则属性信息熵定义为：</h4>

<p>$$\sum _{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)$$</p>

<h4 id="信息增益-度量样本集合根据特定属性-a-分割后信息熵降低水平-偏好类别数多的属性-信息增益越大-分割后纯度越大-定义为"><strong>信息增益：</strong>度量样本集合根据特定属性$a$分割后信息熵降低水平，偏好类别数多的属性，信息增益越大，分割后纯度越大，定义为：</h4>

<p>$$Gain(D,a)=Ent(D) - \sum _{v=1}^V   \frac{|D^v|}{|D|}Ent(D^v)$$</p>

<h4 id="信息增益率-度量样本集合根据特定属性-a-分割后信息熵降低程度-偏好类别数较少的属性-信息增益率越大-分割后纯度越大-定义为"><strong>信息增益率：</strong>度量样本集合根据特定属性$a$分割后信息熵降低程度，偏好类别数较少的属性，信息增益率越大，分割后纯度越大，定义为：</h4>

<p>$$Gain-ratio(D,a) = \frac{Gain(D,a)}{-\sum _{v=1}^V \frac{|D^v|}{|D|} log\frac{|D^v|}{|D|} }$$</p>

<h4 id="基尼系数-度量样本集合纯度-越小越纯-直观上代表从样本集合中抽出两个样本-它们类别不一致的概率-定义为"><strong>基尼系数：</strong>度量样本集合纯度，越小越纯(直观上代表从样本集合中抽出两个样本，它们类别不一致的概率)，定义为：</h4>

<p>$$Gini(D) = 1 - \sum _{i=1}^K p_i^2$$</p>

<h4 id="属性基尼系数-度量样本集合按照特定属性-a-分割后纯度-越小越纯-定义为"><strong>属性基尼系数：</strong>度量样本集合按照特定属性$a$分割后纯度，越小越纯，定义为：</h4>

<p>$$Gini-index(D,a) = \sum _{v=1}^V \frac{|D^v|}{|D|}Gini(D^v)$$</p>

<hr />

<h3 id="2-决策树">2. 决策树</h3>

<h4 id="id3-分类树-采取信息增益率作为最优化分标准"><strong>ID3</strong>：分类树，采取信息增益率作为最优化分标准；</h4>

<h4 id="c4-5-分类树-二分法离散化连续值-划分时-先选择信息增益高于平均水平的特征-再选择信息增益率最大的"><strong>C4.5</strong>：分类树，二分法离散化连续值，划分时，先选择信息增益高于平均水平的特征，再选择信息增益率最大的；</h4>

<h4 id="cart-分类树-回归树-作为分类树时以属性基尼系数作为最优划分标准-作为回归树时参考-回归树-https-blog-csdn-net-weixin-40604987-article-details-79296427"><strong>CART</strong>：分类树/回归树，作为分类树时以属性基尼系数作为最优划分标准；作为回归树时参考<a href="https://blog.csdn.net/weixin_40604987/article/details/79296427">回归树</a></h4>

<h4 id="基本算法"><strong>基本算法</strong>：</h4>

<p><figure><img src="/images/ring.svg" data-sizes="auto" data-src="http://m.qpic.cn/psb?/V12HCzzo2MbQyJ/lEVEbRTjNgloFqDcAoGU*6LlCbgXU.6nhXkGKmq3qEE!/b/dFMBAAAAAAAA&amp;bo=NgKSAQAAAAADB4U!&amp;rf=viewer_4" alt="algorithm" class="lazyload"><figcaption class="image-caption">algorithm</figcaption></figure></p>

<h4 id="剪枝-预剪枝在构建决策树时评估是否会带来泛化性的提升而选择是否分隔-训练速度快但是容易欠拟合-后剪枝从构建的决策树自叶节点向上-若将叶节点与父节点合并会提升泛化性则进行合并"><strong>剪枝</strong>：预剪枝在构建决策树时评估是否会带来泛化性的提升而选择是否分隔，训练速度快但是容易欠拟合；后剪枝从构建的决策树自叶节点向上，若将叶节点与父节点合并会提升泛化性则进行合并；</h4>

<hr />

<h3 id="3-随机森林">3. 随机森林</h3>

<h4 id="bagging-bootstrap-aggregating-每次不放回采样m个样本进行训练-得到t个模型-分类则投票法-回归则平均法-bootstrap方法每次约能涵盖63-2-的原始样本-剩余的36-8-可用作包外估计"><strong>Bagging(Bootstrap Aggregating)</strong>：每次不放回采样m个样本进行训练，得到T个模型，分类则投票法，回归则平均法；Bootstrap方法每次约能涵盖63.2%的原始样本，剩余的36.8%可用作包外估计；</h4>

<h4 id="随机森林-基学习器是决策树-在bagging的基础上-每次划分特征时-先随机选择k个特征-然后在这些特征中选择最优的-最终投票产生结果"><strong>随机森林</strong>：基学习器是决策树，在Bagging的基础上，每次划分特征时，先随机选择k个特征，然后在这些特征中选择最优的，最终投票产生结果；</h4>

<hr />

<h4 id="参考资料">参考资料：</h4>

<ol>
<li>《机器学习》，周志华，清华大学出版社，2017</li>
<li>《统计学习方法》，李航，清华大学出版社，2012</li>
</ol>

    </div>

    <div class="post-copyright">
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://hellosilicat.github.io/posts/dt-rf/>https://hellosilicat.github.io/posts/dt-rf/</span>
            </p>
            
            
    </div>

  
    <div class="post-tags">
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://hellosilicat.github.io/">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://hellosilicat.github.io/posts/2lr/" class="prev" rel="prev" title="Linear Regression and Logistic Regression"><i class="iconfont icon-left"></i>&nbsp;Linear Regression and Logistic Regression</a>
         
        
        <a href="https://hellosilicat.github.io/posts/svm/" class="next" rel="next" title="Support Vector Machine">Support Vector Machine&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>












    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  



     </div>
  </body>
</html>
