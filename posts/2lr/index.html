<!DOCTYPE html>
<html lang="en">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  
  
  
  
  <link rel="prev" href="https://hellosilicat.github.io/posts/confusion/" />
  <link rel="next" href="https://hellosilicat.github.io/posts/dt-rf/" />
  <link rel="canonical" href="https://hellosilicat.github.io/posts/2lr/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           Linear Regression and Logistic Regression | Jialiang Pei
       
  </title>
  <meta name="title" content="Linear Regression and Logistic Regression | Jialiang Pei">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https:\/\/hellosilicat.github.io\/"
    },
    "articleSection" : "posts",
    "name" : "Linear Regression and Logistic Regression",
    "headline" : "Linear Regression and Logistic Regression",
    "description" : "1. 线性回归(单变量) 优化目标： 以均方误差为度量，损失函数定义为$E=\\sum_{i=1}^n(y_i-wx_i-b)^2$，优化目标为：$\\min\\limits_{(w,b)} E $\n求解： 求导得：$$\\frac{\\partial E}{\\partial w}=2\\big(w\\sum_{i=1}^nx_i^2-\\sum_{i=1}^n(y_i-b)x_i\\big)$$ $$\\frac{\\partial E}{\\partial b}=2\\big(nb-\\sum_{i=1}^n(y_i-wx_i)\\big)$$\n令偏导为零得(其中$\\overline x = \\frac{1}{n}x_i$)：$$w=\\frac{\\sum_{i=1}^ny_i(x_i-\\overline x)}{\\sum_{i=1}^nx_i^2-\\frac{1}{n}(\\sum_{i=1}^nx_i)^2}$$ $$b=\\frac{1}{n}\\sum_{i=1}^n(y_i-wx_i)$$\n2. 线性回归(多变量) 优化目标： 令$w= (w_{original};b), X=(X_{original};1)$，损失函数定义为$E=(y-Xw)^T(y-Xw)$，优化目标为:$\\min\\limits_w E$\n求解：仍然是凸函数，矩阵求导后置零计算参数。 求导得：$$\\frac{\\partial E}{\\partial w} = 2X^T(Xw - y)$$\n令导数为零($X^TX$为满秩矩阵或正定矩阵时，否则无解或多解)得：$$w=(X^TX)^{-1}X^Ty$$\n3. 逻辑斯蒂回归 优化目标： 令$w=(w_{original};b),x_i=(x_i;1)$，在逻辑斯蒂回归中，$h(x_i)=\\frac{1}{1\x2be^{-(w^Tx_i)}}$将线性回归的结果映射到$(0,1)$上(Logisitic Distribution)，其值可视作样本为正类$1$的概率(置信度)；若$p(y_i|x_i)$表示样本$x_i$被预测正确的概率，则可重写为：$p(y_i|x_i)=h(x_i)^{y_i}· (1-h(x_i))^{1-y_i}$。\n假设样本之间独立，则样本集的似然函数为$\\prod _{i=1}^nh(x_i)^{y_i}· (1-h(x_i))^{1-y_i}$，对数变换后得：$$L(w)=\\sum _{i=1}^n y_i log\\big(h(x_i)\\big) \x2b(1-y_i)log\\big(1-h(x_i)\\big)$$ 由极大似然法，优化目标为：$\\min\\limits_w (-L)$\n求解：似然函数可通过凸优化的方式求解，这里采用梯度下降法。 不妨设$z = w^Tx_i$，对于参数$w_j$，计算偏导为： \\begin{equation}\\begin{split} \\frac{\\partial{(-L)}}{\\partial w_j}\x26amp;=-\\sum _{i=1}^n x_i^j·\\frac{e^{-z}}{(1\x2be^{-z})^2} · \\big( \\frac{y _i}{h(x_i)} - \\frac{1-y _i}{1-h(x_i)} \\big) \\\\\n\x26amp;=-\\sum _{i=1}^n x_i^j·\\frac{e^{-z}}{(1\x2be^{-z})^2} · \\big( y _i(1\x2be^{-z}) - \\frac{(1-y _i)(1\x2be^{-z})}{e^{-z}} \\big)\\\\",
    "inLanguage" : "en",
    "author" : "",
    "creator" : "",
    "publisher": "",
    "accountablePerson" : "",
    "copyrightHolder" : "",
    "copyrightYear" : "2019",
    "datePublished": "2019-10-12 14:37:05 \x2b0800 CST",
    "dateModified" : "2019-10-12 14:37:05 \x2b0800 CST",
    "url" : "https:\/\/hellosilicat.github.io\/posts\/2lr\/",
    "wordCount" : "123",
    "keywords" : [  "Jialiang Pei"]
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://hellosilicat.github.io/">Jialiang Pei</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/life/" title="">Life</a>
                
                <a class="menu-item" href="/" title="">Sci &amp; Tech</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-xihuan"></i></a>&nbsp;<a href="https://hellosilicat.github.io/">Jialiang Pei</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/life/" title="">Life</a>
                
                <a class="menu-item" href="/" title="">Sci &amp; Tech</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Linear Regression and Logistic Regression</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://hellosilicat.github.io/" rel="author"></a> with ♥ 
                <span class="post-time">
                on <time datetime=2019-10-12 itemprop="datePublished">October 12, 2019</time>
                </span>
                in
                
        </div>
    </header>
    <div class="post-content">
        

        

        
        
     
          
          
          

          
          
          

          

<h3 id="1-线性回归-单变量">1. 线性回归(单变量)</h3>

<h4 id="优化目标"><strong>优化目标：</strong></h4>

<p>以均方误差为度量，损失函数定义为$E=\sum_{i=1}^n(y_i-wx_i-b)^2$，优化目标为：$\min\limits_{(w,b)} E $</p>

<h4 id="求解"><strong>求解：</strong></h4>

<p>求导得：$$\frac{\partial E}{\partial w}=2\big(w\sum_{i=1}^nx_i^2-\sum_{i=1}^n(y_i-b)x_i\big)$$ $$\frac{\partial E}{\partial b}=2\big(nb-\sum_{i=1}^n(y_i-wx_i)\big)$$</p>

<p>令偏导为零得(其中$\overline x = \frac{1}{n}x_i$)：$$w=\frac{\sum_{i=1}^ny_i(x_i-\overline x)}{\sum_{i=1}^nx_i^2-\frac{1}{n}(\sum_{i=1}^nx_i)^2}$$ $$b=\frac{1}{n}\sum_{i=1}^n(y_i-wx_i)$$</p>

<hr />

<h3 id="2-线性回归-多变量">2. 线性回归(多变量)</h3>

<h4 id="优化目标-1"><strong>优化目标：</strong></h4>

<p>令$w= (w_{original};b), X=(X_{original};1)$，损失函数定义为$E=(y-Xw)^T(y-Xw)$，优化目标为:$\min\limits_w E$</p>

<h4 id="求解-仍然是凸函数-矩阵求导后置零计算参数"><strong>求解：</strong>仍然是凸函数，矩阵求导后置零计算参数。</h4>

<p>求导得：$$\frac{\partial E}{\partial w} = 2X^T(Xw - y)$$</p>

<p>令导数为零($X^TX$为满秩矩阵或正定矩阵时，否则无解或多解)得：$$w=(X^TX)^{-1}X^Ty$$</p>

<hr />

<h3 id="3-逻辑斯蒂回归">3. 逻辑斯蒂回归</h3>

<h4 id="优化目标-2"><strong>优化目标：</strong></h4>

<p>令$w=(w_{original};b),x_i=(x_i;1)$，在逻辑斯蒂回归中，$h(x_i)=\frac{1}{1+e^{-(w^Tx_i)}}$将线性回归的结果映射到$(0,1)$上(Logisitic Distribution)，其值可视作样本为正类$1$的概率(置信度)；若$p(y_i|x_i)$表示样本$x_i$被预测正确的概率，则可重写为：$p(y_i|x_i)=h(x_i)^{y_i}· (1-h(x_i))^{1-y_i}$。</p>

<p>假设样本之间独立，则样本集的似然函数为$\prod _{i=1}^nh(x_i)^{y_i}· (1-h(x_i))^{1-y_i}$，对数变换后得：$$L(w)=\sum _{i=1}^n y_i log\big(h(x_i)\big) +(1-y_i)log\big(1-h(x_i)\big)$$
由极大似然法，优化目标为：$\min\limits_w (-L)$</p>

<h4 id="求解-似然函数可通过凸优化的方式求解-这里采用梯度下降法"><strong>求解</strong>：似然函数可通过凸优化的方式求解，这里采用梯度下降法。</h4>

<p>不妨设$z = w^Tx_i$，对于参数$w_j$，计算偏导为：
\begin{equation}\begin{split}
\frac{\partial{(-L)}}{\partial w_j}&amp;=-\sum _{i=1}^n x_i^j·\frac{e^{-z}}{(1+e^{-z})^2} · \big( \frac{y _i}{h(x_i)} - \frac{1-y _i}{1-h(x_i)}  \big) \\<br />
&amp;=-\sum _{i=1}^n x_i^j·\frac{e^{-z}}{(1+e^{-z})^2} · \big( y _i(1+e^{-z}) - \frac{(1-y _i)(1+e^{-z})}{e^{-z}} \big)\\<br />
&amp; = -\sum _{i=1}^n x_i^j·\frac{e^{-z}}{1+e^{-z}} · (y _i - \frac{1-y _i}{e^{-z}}) \\<br />
&amp; = -\sum _{i=1}^n x_i^j· \big[  (1-h(x_i))y_i - h(x_i)(1-y _i)  \big] \\<br />
&amp; = \sum _{i=1}^n x_i^j (h(x_i)-y_i)
\end{split}\end{equation}</p>

<p>若学习率为$\alpha$，则每次迭代后：$$w _j = w _j - \alpha ·  \frac{\partial{(-L)}}{\partial w_j}$$</p>

<hr />

<h4 id="参考资料">参考资料：</h4>

<ol>
<li>《机器学习》，周志华，清华大学出版社，2017</li>
<li>《统计学习方法》，李航，清华大学出版社，2012</li>
</ol>

    </div>

    <div class="post-copyright">
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://hellosilicat.github.io/posts/2lr/>https://hellosilicat.github.io/posts/2lr/</span>
            </p>
            
            
    </div>

  
    <div class="post-tags">
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="https://hellosilicat.github.io/">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://hellosilicat.github.io/posts/confusion/" class="prev" rel="prev" title="Confusion Matrix and Measurement"><i class="iconfont icon-left"></i>&nbsp;Confusion Matrix and Measurement</a>
         
        
        <a href="https://hellosilicat.github.io/posts/dt-rf/" class="next" rel="next" title="Decision Tree and Random Forest">Decision Tree and Random Forest&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>












    
    
    <script src="/js/vendor_no_gallery.min.js" async=""></script>
    
  



     </div>
  </body>
</html>
