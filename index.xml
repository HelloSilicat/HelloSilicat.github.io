<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kanata</title>
    <link>https://hellosilicat.github.io/</link>
    <description>Recent content on Kanata</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 14 Oct 2019 14:04:29 +0800</lastBuildDate>
    
	<atom:link href="https://hellosilicat.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Decision Tree and Random Forest</title>
      <link>https://hellosilicat.github.io/post/dt-rf/</link>
      <pubDate>Mon, 14 Oct 2019 14:04:29 +0800</pubDate>
      
      <guid>https://hellosilicat.github.io/post/dt-rf/</guid>
      <description> 1. 基础 信息熵(information entropy)： 度量样本集合纯度，越小越纯；若当前样本集合$D$中第$i$类样本所占的比例为$p_i(i=1,2,&amp;hellip;,K)$，则信息熵定义为： $$Ent(D) = -\sum _{i=1}^K p_i logp_i$$
属性信息熵：度量样本集合按照特定属性分割后的信息熵；若样本集合在属性取$v$值时的子集为$D^v(v=1,2,&amp;hellip;,V)$，则属性信息熵定义为： $$\sum _{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)$$
信息增益：度量样本集合根据特定属性$a$分割后信息熵降低水平，偏好类别数多的属性，信息增益越大，分割后纯度越大，定义为： $$Gain(D,a)=Ent(D) - \sum _{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)$$
信息增益率：度量样本集合根据特定属性$a$分割后信息熵降低程度，偏好类别数较少的属性，信息增益率越大，分割后纯度越大，定义为： $$Gain-ratio(D,a) = \frac{Gain(D,a)}{-\sum _{v=1}^V \frac{|D^v|}{|D|} log\frac{|D^v|}{|D|} }$$
基尼系数：度量样本集合纯度，越小越纯(直观上代表从样本集合中抽出两个样本，它们类别不一致的概率)，定义为： $$Gini(D) = 1 - \sum _{i=1}^K p_i^2$$
属性基尼系数：度量样本集合按照特定属性$a$分割后纯度，越小越纯，定义为： $$Gini-index(D,a) = \sum _{v=1}^V \frac{|D^v|}{|D|}Gini(D^v)$$
2. 决策树 ID3：分类树，采取信息增益率作为最优化分标准； C4.5：分类树，二分法离散化连续值，划分时，先选择信息增益高于平均水平的特征，再选择信息增益率最大的； CART：分类树/回归树，作为分类树时以属性基尼系数作为最优划分标准；作为回归树时参考回归树 基本算法： 剪枝：预剪枝在构建决策树时评估是否会带来泛化性的提升而选择是否分隔，训练速度快但是容易欠拟合；后剪枝从构建的决策树自叶节点向上，若将叶节点与父节点合并会提升泛化性则进行合并； 3. 随机森林 Bagging(Bootstrap Aggregating)：每次不放回采样m个样本进行训练，得到T个模型，分类则投票法，回归则平均法；Bootstrap方法每次约能涵盖63.2%的原始样本，剩余的36.8%可用作包外估计； 随机森林：基学习器是决策树，在Bagging的基础上，每次划分特征时，先随机选择k个特征，然后在这些特征中选择最优的，最终投票产生结果； </description>
    </item>
    
    <item>
      <title>Linear Regression and Logistic Regression</title>
      <link>https://hellosilicat.github.io/post/2lr/</link>
      <pubDate>Sat, 12 Oct 2019 14:37:05 +0800</pubDate>
      
      <guid>https://hellosilicat.github.io/post/2lr/</guid>
      <description>1. 线性回归(单变量) 优化目标： 以均方误差为度量，损失函数定义为$E=\sum_{i=1}^n(y_i-wx_i-b)^2$，优化目标为：$\min\limits_{(w,b)} E $
求解： 求导得：$$\frac{\partial E}{\partial w}=2\big(w\sum_{i=1}^nx_i^2-\sum_{i=1}^n(y_i-b)x_i\big)$$ $$\frac{\partial E}{\partial b}=2\big(nb-\sum_{i=1}^n(y_i-wx_i)\big)$$
令偏导为零得(其中$\overline x = \frac{1}{n}x_i$)：$$w=\frac{\sum_{i=1}^ny_i(x_i-\overline x)}{\sum_{i=1}^nx_i^2-\frac{1}{n}(\sum_{i=1}^nx_i)^2}$$ $$b=\frac{1}{n}\sum_{i=1}^n(y_i-wx_i)$$
2. 线性回归(多变量) 优化目标： 令$w= (w_{original};b), X=(X_{original};1)$，损失函数定义为$E=(y-Xw)^T(y-Xw)$，优化目标为:$\min\limits_w E$
求解：仍然是凸函数，矩阵求导后置零计算参数。 求导得：$$\frac{\partial E}{\partial w} = 2X^T(Xw - y)$$
令导数为零($X^TX$为满秩矩阵或正定矩阵时，否则无解或多解)得：$$w=(X^TX)^{-1}X^Ty$$
3. 逻辑斯蒂回归 优化目标： 令$w=(w_{original};b),x_i=(x_i;1)$，在逻辑斯蒂回归中，$h(x_i)=\frac{1}{1+e^{-(w^Tx_i)}}$将线性回归的结果映射到$(0,1)$上(Logisitic Distribution)，其值可视作样本为正类$1$的概率(置信度)；若$p(y_i|x_i)$表示样本$x_i$被预测正确的概率，则可重写为：$p(y_i|x_i)=h(x_i)^{y_i}· (1-h(x_i))^{1-y_i}$。
假设样本之间独立，则样本集的似然函数为$\prod _{i=1}^nh(x_i)^{y_i}· (1-h(x_i))^{1-y_i}$，对数变换后得：$$L(w)=\sum _{i=1}^n y_i log\big(h(x_i)\big) +(1-y_i)log\big(1-h(x_i)\big)$$ 由极大似然法，优化目标为：$\min\limits_w (-L)$
求解：似然函数可通过凸优化的方式求解，这里采用梯度下降法。 不妨设$z = w^Tx_i$，对于参数$w_j$，计算偏导为： \begin{equation}\begin{split} \frac{\partial{(-L)}}{\partial w_j}&amp;amp;=-\sum _{i=1}^n x_i^j·\frac{e^{-z}}{(1+e^{-z})^2} · \big( \frac{y _i}{h(x_i)} - \frac{1-y _i}{1-h(x_i)} \big) \\
&amp;amp;=-\sum _{i=1}^n x_i^j·\frac{e^{-z}}{(1+e^{-z})^2} · \big( y _i(1+e^{-z}) - \frac{(1-y _i)(1+e^{-z})}{e^{-z}} \big)\\</description>
    </item>
    
    <item>
      <title>Confusion Matrix and Measurement</title>
      <link>https://hellosilicat.github.io/post/confusion/</link>
      <pubDate>Thu, 10 Oct 2019 12:31:14 +0800</pubDate>
      
      <guid>https://hellosilicat.github.io/post/confusion/</guid>
      <description> 在有监督分类学习中，混淆矩阵(confusion matrix)可用来描述模型在数据集上的预测状况，如针对$k$分类问题，混淆矩阵$C$为$k$阶方阵，其中$C_{i,j}(i,j\le k)$表示实际类别为$i$而模型预测类别为$j$的样本数；在混淆矩阵的基础上，我们可以定义各种度量用以评估模型性能，本文将介绍：准确率(accuracy)、精确率P(precision)、召回率R(recall)、F1值、P-R曲线与BEP(break-even point)、ROC曲线与AUC。
以二分类问题为例，类别包含正类$P$、负类$N$，其混淆矩阵如下图所示。其中：
 $TP$：实际为正类且预测为正类的样本数 $FN$：实际为正类而预测为负类的样本数 $FP$：实际为负类而预测为正类的样本数 $TN$：实际为负类而预测为负类的样本数  准确率Accuracy指在所有样本中模型预测正确的比例，即：$$Accuracy=\frac{TP+TN}{TP+FN+FP+TN}$$
在类别不均衡问题中，准确率不能很好的度量性能，例如在99个正类和1个负类的数据集中，即使盲猜正类也能获得很高的准确率，然而这样的模型不具有泛化性，因此需要同时考虑精确率和召回率。
精确率P指在预测为正类的样本中预测正确的比例，即：$$Precision=\frac{TP}{TP+FP}$$
召回率R指在实际为正类的样本中预测正确的比例，即：$$Recall=\frac{TP}{TP+FN}$$
如何理解精确率和召回率？西瓜书中有一个例子：你去买西瓜，精确率关注你挑的瓜中有多少比例是好瓜，而召回率更关注有多少比例的好瓜被你挑了出来。
精确率与召回率是负相关的，精确率高时往往召回率会降低，反之亦然。如何综合两者去考量一个模型？P-R曲线与BEP便是方法之一。
P-R曲线横轴是召回率，纵轴是精确率，BEP(break-even point)是指曲线上横纵坐标相等的点，可以认为是平衡点。
如何绘制P-R曲线？对于一个样本集合，根据模型结果或中间值对样本进行排序，靠前的样本有更大概率被分为正类；之后逐个样本作为阈值，比该样本靠前的预测为正类，其余为负类，每次计算Precision和Recall，这样得到一系列二维点，绘制即可得到该曲线，通常情况下曲线为离散状，随数据集规模增加而更平滑。
如下图，当模型A的P-R曲线包含模型B的P-R曲线时，可认为A的性能更佳，如Model2优于Model1，然而P-R曲线也会出现交叉，此时可根据模型的BEP来判断，如Model3的BEP大于Model2的BEP(处于右上方)，则认为Model3的性能优于Model2。
通过P-R曲线来综合考虑精确率和召回率难免比较麻烦，另一个相对简单但有效的方式是计算F1值，F1值越大，模型性能越好。
F1-Score是精确率P和召回率R的调和平均数，即：$$\frac{1}{F1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})$$
当存在多个混淆矩阵(多次训练或多个数据集等产生)时，F1值可分为macro-F1和micro-F1，两者区别在于粒度不同。
macro-F1是指先计算出每个混淆矩阵的P和R，得到平均值后再计算F1值；
micro-F1是指先计算每个混淆矩阵的TP/FN/FP，得到平均值后计算P和R，最终再计算F1值；
不同的业务场景对精确率和召回率的要求是不同的，例如推荐系统中更关注推荐的东西是用户喜欢的，即更关注精确率，此时可通过加权F1值来评估模型。
加权F1-Score通过调整F1计算公式P、R系数来改变二者的重要程度，即：$$F_\beta=\frac{1}{1+\beta^2}(\frac{1}{P}+\frac{\beta^2}{R})$$
当$\beta=1$时退化成普通F1，当$\beta&amp;gt;1$时更关注召回率R，当$\beta&amp;lt;1$时更关注精确率P(可分别计算P、R的偏导系数，越大说明该因子影响越大)。
与P-R曲线类似的是ROC(Receiver Operating Characteristic)曲线，也是先对样本进行排序，按此顺序逐片段作为正例进行预测，每次计算两个值，然后绘制曲线，不过ROC曲线的横轴是假阳率FPR(False Positive Rate)，纵轴为真阳率TPR(True Positive Rate)，其定义为： $$TPR=\frac{TP}{TP+FN}$$ $$FPR=\frac{FP}{TN+FP}$$
现实任务中，ROC曲线是离散的，如下图，一种绘制方法为首先将样本按照预测结果或中间值进行排序，然后依次将每个样本划分为正例，设正样本个数为$m^+$，负样本个数为$m-$，前一个标记点坐标为$(x,y)$，当前样本实际若为正例，则绘制$(x,y+\frac{1}{m^+})$，当前样本实际若为负例，则绘制$(x+\frac{1}{m^-},y)$，以此类推，ROC曲线必经过$(0,0)$点和$(1,1)$点，分别对应全部预测负类和全部预测正类的情况。
同样，当一个模型的ROC曲线包含包含另一个模型的ROC曲线时(所有点在左上方)，可认为该模型更优，然而面对ROC曲线的情况，需要引入AUC值来衡量模型好坏，AUC越大，说明模型性能更优。
AUC(Area Under ROC Curve)指ROC曲线下方的面积，将$x_{i}$ 按照大小顺序排列，AUC计算公式为(其中$m$指样本集大小)：$$AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)(y_i+y_{i+1})$$
参考资料：  《机器学习》，周志华，清华大学出版社，2017  </description>
    </item>
    
  </channel>
</rss>